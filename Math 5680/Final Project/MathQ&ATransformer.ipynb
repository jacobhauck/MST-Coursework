{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saw43LjtY78K"
      },
      "source": [
        "# Math Q&A Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "module_path = os.path.abspath('.')\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESQ9D1ZPZDf1"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDvOOvZ-XdOn"
      },
      "source": [
        "Summarize dataset structure for the `arithmetic` category."
      ]
    },
    {
      "cell_type": "code",
<<<<<<< HEAD
      "execution_count": 2,
=======
      "execution_count": 4,
>>>>>>> c5516d9a494ee49e79e6041aadedb34f118d31bb
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHDaUJUTSglp",
        "outputId": "ff06fb9a-31e7-46ff-ce4b-3f101f4f0c69"
      },
      "outputs": [
        {
<<<<<<< HEAD
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Type: extrapolate\n",
            "  add_or_sub_big\n",
            "  add_sub_multiple_longer\n",
            "  div_big\n",
            "  mixed_longer\n",
            "  mul_big\n",
            "  mul_div_multiple_longer\n",
            "\n",
            "Data Type: interpolate\n",
            "  add_or_sub\n",
            "  add_or_sub_in_base\n",
            "  add_sub_multiple\n",
            "  div\n",
            "  mixed\n",
            "  mul\n",
            "  mul_div_multiple\n",
            "  nearest_integer_root\n",
            "  simplify_surd\n",
            "\n",
            "Data Type: train-easy\n",
            "  add_or_sub\n",
            "  add_or_sub_in_base\n",
            "  add_sub_multiple\n",
            "  div\n",
            "  mixed\n",
            "  mul\n",
            "  mul_div_multiple\n",
            "  nearest_integer_root\n",
            "  simplify_surd\n",
            "\n",
            "Data Type: train-hard\n",
            "  add_or_sub\n",
            "  add_or_sub_in_base\n",
            "  add_sub_multiple\n",
            "  div\n",
            "  mixed\n",
            "  mul\n",
            "  mul_div_multiple\n",
            "  nearest_integer_root\n",
            "  simplify_surd\n",
            "\n",
            "Data Type: train-medium\n",
            "  add_or_sub\n",
            "  add_or_sub_in_base\n",
            "  add_sub_multiple\n",
            "  div\n",
            "  mixed\n",
            "  mul\n",
            "  mul_div_multiple\n",
            "  nearest_integer_root\n",
            "  simplify_surd\n",
            "\n"
=======
          "ename": "FileNotFoundError",
          "evalue": "[WinError 3] The system cannot find the path specified: 'mathematics_dataset\\\\mathematics_dataset-v1.0'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\hauck\\Projects\\Coursework\\Math 5680\\Final Project\\MathQ&ATransformer.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmath_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m MathDataset\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m data_type, categories \u001b[39min\u001b[39;00m MathDataset\u001b[39m.\u001b[39;49msubcategories()\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData Type: \u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39mfor\u001b[39;00m subcat \u001b[39min\u001b[39;00m categories[\u001b[39m'\u001b[39m\u001b[39marithmetic\u001b[39m\u001b[39m'\u001b[39m]:\n",
            "File \u001b[1;32mc:\\Users\\hauck\\Projects\\Coursework\\Math 5680\\Final Project\\math_dataset.py:54\u001b[0m, in \u001b[0;36mMathDataset.subcategories\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m:return: dictionary of data type -> category -> list of subcategories\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mfor each category in each data type of the dataset\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m subcategories \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 54\u001b[0m \u001b[39mfor\u001b[39;00m data_type \u001b[39min\u001b[39;00m MathDataset\u001b[39m.\u001b[39;49mdata_types():\n\u001b[0;32m     55\u001b[0m   data_type_subcats \u001b[39m=\u001b[39m {}\n\u001b[0;32m     56\u001b[0m   dtype_folder \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MathDataset\u001b[39m.\u001b[39mroot(), data_type)\n",
            "File \u001b[1;32mc:\\Users\\hauck\\Projects\\Coursework\\Math 5680\\Final Project\\math_dataset.py:27\u001b[0m, in \u001b[0;36mMathDataset.data_types\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_types\u001b[39m():\n\u001b[0;32m     22\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m  :return: data types in the dataset (train-easy, train-hard,\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m  eval, etc.)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m---> 27\u001b[0m     d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(MathDataset\u001b[39m.\u001b[39;49mroot())\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MathDataset\u001b[39m.\u001b[39mroot(), d))\n\u001b[0;32m     29\u001b[0m   )\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'mathematics_dataset\\\\mathematics_dataset-v1.0'"
>>>>>>> c5516d9a494ee49e79e6041aadedb34f118d31bb
          ]
        }
      ],
      "source": [
        "from math_dataset import MathDataset\n",
        "\n",
        "for data_type, categories in MathDataset.subcategories().items():\n",
        "  print(f'Data Type: {data_type}')\n",
        "  for subcat in categories['arithmetic']:\n",
        "    print(f'  {subcat}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_W8QrwlYK60"
      },
      "source": [
        "Print some example questions and answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy3v679TXsSV",
        "outputId": "ab755475-ea10-4b74-85b6-5bbb239e7cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is -15845 minus -35?\n",
            "Answer: -15810\n",
            "\n",
            "Question: Work out 0.95 - 2721.\n",
            "Answer: -2720.05\n",
            "\n",
            "Question: Sum -20.4 and -0.024.\n",
            "Answer: -20.424\n",
            "\n",
            "Question: Calculate -1.4968 + 6.\n",
            "Answer: 4.5032\n",
            "\n",
            "Question: What is -0.3 less than 14240?\n",
            "Answer: 14240.3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_dataset = MathDataset('train-easy', 'arithmetic', 'add_or_sub')\n",
        "\n",
        "for question, answer in zip(*test_dataset[5000:5005]):\n",
        "  print(f'Question: {question}')\n",
        "  print(f'Answer: {answer}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7hziDg2xdn7"
      },
      "source": [
        "## Setup for Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd0ZiueUx31A"
      },
      "source": [
        "Determine token set for arithmetic training easy. Takes ~30s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAAncYCLx3oG",
        "outputId": "9e43e835-5829-461e-bc5b-eff0f4ace74d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(' ',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " '?',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import utils\n",
        "\n",
        "# load all arithmetic training easy subcategories\n",
        "arthimetic_easy_subcats = MathDataset.subcategories()['train-easy']['arithmetic']\n",
        "datasets = [\n",
        "    MathDataset('train-easy', 'arithmetic', s)\n",
        "    for s in arthimetic_easy_subcats\n",
        "]\n",
        "\n",
        "# put together all subcategories\n",
        "arithmetic_easy = torch.utils.data.ConcatDataset(datasets)\n",
        "\n",
        "# find all possible tokens\n",
        "arithmetic_easy_tokens = utils.token_set(arithmetic_easy)\n",
        "\n",
        "arithmetic_easy_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('tokens.txt', 'w') as f:\n",
        "    for t in arithmetic_easy_tokens:\n",
        "        f.write(t + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwq9wxIB5lvA"
      },
      "source": [
        "Evaluate input-output sequence lengths. Takes ~1min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "tfmprD4E5lBI",
        "outputId": "b69f5521-e092-422d-d11b-e8fa1ffb4f88"
      },
      "outputs": [],
      "source": [
        "utils.plot_length_histogram(arithmetic_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llb32_RELpMa"
      },
      "source": [
        "## Exploring Token Embeddings and Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfiUh707Lp_6"
      },
      "outputs": [],
      "source": [
        "from transformer import Transformer, TokenEmbedding\n",
        "\n",
        "transformer = Transformer(\n",
        "    TokenEmbedding(arithmetic_easy_tokens, 6),  # 6 = d_model\n",
        "    30,   # = max_output_length\n",
        "    5,    # = n_encoder_layers\n",
        "    5,    # = n_decoder_layers\n",
        "    1,    # = n_heads\n",
        "    1024  # = d_ff\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KRegsZ1Pf3v",
        "outputId": "f1b89bbd-713e-4fd5-dc12-01fda21e38eb"
      },
      "outputs": [],
      "source": [
        "sample_questions = [arithmetic_easy[i][0] for i in range(5)]\n",
        "sample_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixuSqIznOtU-",
        "outputId": "8f5ca9a3-6f94-4241-be7e-fd0a5b673383"
      },
      "outputs": [],
      "source": [
        "sample_indices = transformer.token_embedding.indices(sample_questions)\n",
        "sample_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZKdL-1kTGry",
        "outputId": "800129f0-8bf9-45f1-906c-a6f73b135715"
      },
      "outputs": [],
      "source": [
        "sample_unembedded = transformer.token_embedding.unembed(sample_indices)\n",
        "sample_unembedded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YBz97qNTOES",
        "outputId": "ab44af5c-df47-466f-dea6-6f2e5a6eae4a"
      },
      "outputs": [],
      "source": [
        "sample_unembedded_special = transformer.token_embedding.unembed(\n",
        "    sample_indices, include_special=True\n",
        ")\n",
        "sample_unembedded_special"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oswg-yHLQaL9",
        "outputId": "4043d7e4-5bf7-459d-8d52-d82ea798a3a4"
      },
      "outputs": [],
      "source": [
        "sample_token_embeddings = transformer.token_embedding(sample_indices)\n",
        "sample_token_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2_7C5k4RfCk",
        "outputId": "17737571-b840-4ded-9cbc-11c210302be0"
      },
      "outputs": [],
      "source": [
        "def print_full(matrix, digits='.02f'):\n",
        "  for r in range(matrix.shape[0]):\n",
        "    for c in range(matrix.shape[1]):\n",
        "      print(f'{float(matrix[r, c]):{digits}}', end=' ')\n",
        "    print()\n",
        "  print()\n",
        "\n",
        "\n",
        "mask = transformer.input_attention_mask(sample_indices)\n",
        "for index_seq, mask in zip(sample_indices, mask):\n",
        "  print('Token sequence indices and input mask matrix')\n",
        "  print_full(torch.cat([index_seq[None], mask]), digits='g')\n",
        "\n",
        "  print('Post-softmax')\n",
        "  print_full(torch.nn.functional.softmax(mask, dim=1), digits='.4f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Mi4DIcgSaHG"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'arithmetic_easy' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\hauck\\Projects\\Coursework\\Math 5680\\Final Project\\MathQ&ATransformer.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sample_outputs \u001b[39m=\u001b[39m [arithmetic_easy[i][\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m5\u001b[39;49m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sample_output_indices \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtoken_embedding\u001b[39m.\u001b[39mindices(sample_outputs)\n",
            "\u001b[1;32mc:\\Users\\hauck\\Projects\\Coursework\\Math 5680\\Final Project\\MathQ&ATransformer.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m sample_outputs \u001b[39m=\u001b[39m [arithmetic_easy[i][\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hauck/Projects/Coursework/Math%205680/Final%20Project/MathQ%26ATransformer.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m sample_output_indices \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtoken_embedding\u001b[39m.\u001b[39mindices(sample_outputs)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'arithmetic_easy' is not defined"
          ]
        }
      ],
      "source": [
        "sample_outputs = [arithmetic_easy[i][1] for i in range(5)]\n",
        "sample_output_indices = transformer.token_embedding.indices(sample_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmESJ0IYW7oO",
        "outputId": "ee4c89e6-b482-426a-a3d0-fe9311e55ed3"
      },
      "outputs": [],
      "source": [
        "sample_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fksug2sLW9IJ",
        "outputId": "a5b05068-cf62-4667-a4d4-3eb3b63d319b"
      },
      "outputs": [],
      "source": [
        "sample_output_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ubq0_CoW-tj",
        "outputId": "acacb810-b2b9-4ade-ac96-78cd5d23982f"
      },
      "outputs": [],
      "source": [
        "mask = transformer.output_attention_mask(sample_output_indices)\n",
        "for index_seq, mask in zip(sample_output_indices, mask):\n",
        "  print('Token sequence indices and output self-attention mask matrix')\n",
        "  print_full(torch.cat([index_seq[None], mask]), digits='g')\n",
        "\n",
        "  print('Post-softmax')\n",
        "  print_full(torch.nn.functional.softmax(mask, dim=1), digits='.4f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdSlMn0WXJdG",
        "outputId": "df78f36c-9515-4fb9-e91e-67defb3b9a63"
      },
      "outputs": [],
      "source": [
        "mask = transformer.cross_attention_mask(sample_indices, sample_output_indices)\n",
        "for index_seq, mask in zip(sample_indices, mask):\n",
        "  print('Token sequence indices and output cross-attention mask matrix')\n",
        "  print_full(torch.cat([index_seq[None], mask]), digits='g')\n",
        "\n",
        "  print('Post-softmax')\n",
        "  print_full(torch.nn.functional.softmax(mask, dim=1), digits='.4f')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9PsqWbSpIpV"
      },
      "source": [
        "## Transformer Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TxlYxEyUosL"
      },
      "outputs": [],
      "source": [
        "from training import QATransformerTrainer, WarmupLRScheduleCallback,\\\n",
        "  SavePeriodicallyCallback, make_loss_fn\n",
        "\n",
        "model = Transformer(\n",
        "    TokenEmbedding(arithmetic_easy_tokens, 128),\n",
        "    30, 5, 5, 2, 512, p_dropout=.025\n",
        ").cuda()\n",
        "\n",
        "ar_easy_dl = torch.utils.data.DataLoader(\n",
        "    arithmetic_easy, batch_size=512, shuffle=True,\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    betas=(.9, .98),\n",
        "    eps=1e-9\n",
        ")\n",
        "\n",
        "lr_schedule_callback = WarmupLRScheduleCallback(\n",
        "    15000, model.token_embedding.d, optim\n",
        ")\n",
        "\n",
        "cel = torch.nn.CrossEntropyLoss(\n",
        "    ignore_index=model.token_embedding.pad_index, label_smoothing=.05\n",
        ")\n",
        "\n",
        "loss_fn = make_loss_fn(cel, model.token_embedding.pad_index)\n",
        "\n",
        "trainer = QATransformerTrainer('model4', model, ar_easy_dl, optim, loss_fn, 100)\n",
        "\n",
        "# save every 900s = 15min\n",
        "save_callback = SavePeriodicallyCallback(trainer, 900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pT7ZOr5GUqRB",
        "outputId": "080f75b1-7e9e-434d-a394-2cbcc2f4dd79"
      },
      "outputs": [],
      "source": [
        "losses, accuracies = trainer.train(\n",
        "    epochs=4,\n",
        "    batch_callbacks=[save_callback],\n",
        "    verbosity=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from simple_dataset import SimpleDataset1\n",
        "\n",
        "simple_dataset = SimpleDataset1(1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from training import QATransformerTrainer, WarmupLRScheduleCallback,\\\n",
        "  SavePeriodicallyCallback, make_loss_fn\n",
        "\n",
        "model = Transformer(\n",
        "    TokenEmbedding(arithmetic_easy_tokens, 128),\n",
        "    30, 5, 5, 2, 512, p_dropout=.025\n",
        ").cuda()\n",
        "\n",
        "ar_easy_dl = torch.utils.data.DataLoader(\n",
        "    arithmetic_easy, batch_size=512, shuffle=True,\n",
        ")\n",
        "\n",
        "optim = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    betas=(.9, .98),\n",
        "    eps=1e-9\n",
        ")\n",
        "\n",
        "lr_schedule_callback = WarmupLRScheduleCallback(\n",
        "    15000, model.token_embedding.d, optim\n",
        ")\n",
        "\n",
        "cel = torch.nn.CrossEntropyLoss(\n",
        "    ignore_index=model.token_embedding.pad_index, label_smoothing=.05\n",
        ")\n",
        "\n",
        "loss_fn = make_loss_fn(cel, model.token_embedding.pad_index)\n",
        "\n",
        "trainer = QATransformerTrainer('model4', model, ar_easy_dl, optim, loss_fn, 100)\n",
        "\n",
        "# save every 900s = 15min\n",
        "save_callback = SavePeriodicallyCallback(trainer, 900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses, accuracies = trainer.train(\n",
        "    epochs=2,\n",
        "    batch_callbacks=[save_callback],\n",
        "    verbosity=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arthimetic_inter_subcats = MathDataset.subcategories()['interpolate']['arithmetic']\n",
        "datasets = [\n",
        "    MathDataset('interpolate', 'arithmetic', s)\n",
        "    for s in arthimetic_inter_subcats\n",
        "]\n",
        "\n",
        "interpolate_data = torch.utils.data.ConcatDataset(datasets)\n",
        "\n",
        "interpolate_dl = torch.utils.data.DataLoader(\n",
        "    interpolate_data, batch_size=512, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = next(iter(ar_easy_dl))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for q, a in zip(*batch):\n",
        "        print('Question:', q)\n",
        "        print('Answer:', a)\n",
        "        print('Model Answer:', model(q))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model('Calculate -(2*4 - (3 + 4))')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "-(2*4 - (3 + 4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
