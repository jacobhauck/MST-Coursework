{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math 5680 Final Project -- Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a folder in which to save the experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DATABASE = 'model5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import simple\n",
    "\n",
    "simple_exp = simple.SimpleDatasetExperiment(MODEL_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_exp.run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77a1d34829a40878d483278d59a88db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 7.09\n",
      "Test accuracy (first): 100.00\n"
     ]
    }
   ],
   "source": [
    "simple_exp.run_evaluation(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a folder in which to save the experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DATABASE = 'model4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import arithmetic_easy\n",
    "\n",
    "ar_easy_exp = arithmetic_easy.ArithmeticEasyExperiment(MODEL_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_easy_exp.run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6ee4452eaa469b95c16138cbd1e4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/599999 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 40.46%\n",
      "Test accuracy (first): 76.35%\n"
     ]
    }
   ],
   "source": [
    "ar_easy_exp.run_evaluation(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try evaluating on the provided testing data, which contains an assortment of easy, medium and hard questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8492939d307a4506b549f41489bb89b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90000 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from math_dataset import MathDataset\n",
    "\n",
    "test_subcats = MathDataset.subcategories()['interpolate']['arithmetic']\n",
    "datasets = [MathDataset('interpolate', 'arithmetic', s) for s in test_subcats]\n",
    "test_dl = torch.utils.data.ConcatDataset(datasets)\n",
    "\n",
    "ar_easy_exp.trainer.load(40)\n",
    "\n",
    "n_total = 0\n",
    "n_correct = 0\n",
    "n_first_correct = 0\n",
    "\n",
    "\n",
    "def evaluate(model_answer, actual_answer):\n",
    "    global n_total, n_correct, n_first_correct\n",
    "\n",
    "    n_total += 1\n",
    "\n",
    "    if model_answer == actual_answer:\n",
    "        n_correct += 1\n",
    "\n",
    "    first = min(len(model_answer), len(actual_answer))\n",
    "    if model_answer[:first] == actual_answer[:first]:\n",
    "        n_first_correct += 1\n",
    "\n",
    "\n",
    "ar_easy_exp.trainer.evaluate(test_dl, evaluate)\n",
    "\n",
    "print(f'Test accuracy: {n_correct / n_total * 100:.02f}%')\n",
    "print(f'Test accuracy (first): {n_first_correct / n_total * 100:.02f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View some sample questions and compare true and model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dl = torch.utils.data.DataLoader(ar_easy_exp.test_dataset, batch_size=64, shuffle=True)\n",
    "sample_it = iter(sample_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = next(sample_it)\n",
    "\n",
    "ar_easy_exp.model.eval()\n",
    "with torch.no_grad():\n",
    "    for q, a in zip(questions, answers):\n",
    "        model_a = ar_easy_exp.model(q)\n",
    "        print(f'Q: {q}')\n",
    "        print(f'A: {a}')\n",
    "        print(f'M: {model_a}')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
