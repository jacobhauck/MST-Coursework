\documentclass{homework}
\input{../homework_shared.tex}
\input{../../standardcmd.tex}

\newcommand{\hwnum}{10}
\renewcommand{\questiontype}{Problem}

\begin{document}
	\maketitle
	
	\question
	Let
	\begin{equation}
		A = \left(\begin{matrix}
			5 & -2 \\
			-4 & 7
		\end{matrix}\right).
	\end{equation}
	Then the eigenvalues of $A$ are the roots $\lambda$ of the equation $(5-\lambda)(7-\lambda) - 8 = 0$. That is, $\lambda^2-12\lambda +27 = 0$, or $(\lambda - 3)(\lambda - 9) = 0$. Thus, the eigenvalues of $A$ are $\lambda_1=3$ and $\lambda_2=9$. This implies that the spectral radius of $A$ is $\rho(A) = \max\{3,9\} = 9$.
	
	By Lemma (I) in the lecture, we can compute $\lVert A \rVert_2$ by computing $\sqrt{\rho(A^TA)}$. Since
	\begin{equation}
		A^TA = \left(\begin{matrix}
			41 & -38 \\
			-38 & 53
		\end{matrix}\right),
	\end{equation}
	we see that the eigenvalues of $A^TA$ are the roots $\sigma$ of the equation $(41-\sigma)(53-\sigma) - 38^2=0$, or $\sigma^2 - 94\sigma + 41\cdot53 - 38^2 = 0$. Then
	\begin{equation}
		\sigma = 47 \pm \sqrt{47^2 - 41\cdot53 + 38^2}= 47\pm\sqrt{1480}.
	\end{equation}
	Therefore, $\rho(A^TA) = 47 + \sqrt{1480}$, and $\lVert A\rVert_2 = \sqrt{47 + \sqrt{1480}} \approx 9.254 \ge \rho(A)$.
	
	By Lemma (I) in the lecture, we can compute $\lVert A\rVert_1$ by computing the maximum absolute column sum. The absolute column sums of $A$ are $5+4=9$, and $2 + 7 = 9$. Therefore, $\lVert A\rVert_1 = 9 \ge \rho(A)$.
	
	By Lemma (I) in the lecture, we can compute $\lVert A \rVert_\infty$ by computing the maximum absolute row sum. The absolute row sums of $A$ are $5 + 2 = 7$, and $4 + 7 = 11$. Therefore, $\lVert A \rVert_\infty = 11 \ge \rho(A)$.
	
	\question
	Let $A = \{a_{ij}\}$ be the tridiagonal matrix with entries
	\begin{equation}
		a_{ij} = \begin{cases}
			4 & \text{if } i= j,\\
			-1 & \text{if } i=j+1 \text{ or } i = j-1,\\
			0 & \text{otherwise}.
		\end{cases}
	\end{equation}
	Suppose that the Jacobi method for solving $Ax = b$ has the form $x^{(k+1)} = Bx^{(k)} + c$. We can compute $B$ and $c$ by the definition of the Jacobi method as $B = D^{-1}(L+U)$, and $c = D^{-1}b$, where $L$, $U$, and $D$ are the lower, upper and diagonal parts of $A$. Clearly, $D^{-1}$ is a diagonal matrix with diagonal elements all equal to $\frac{1}{4}$. Then $B = \{b_{ij}\}$ is the matrix with entries
	\begin{equation}
		b_{ij} = \begin{cases}
			-\frac{1}{4} & \text{if } i=j+1\text{ or }i = j-1,\\
			0 & \text{otherwise}.
		\end{cases}
	\end{equation}
	By Lemma (I) in the lecture, $\lVert B \rVert_1$ is the maximum absolute column sum of $B$. Since each column of $B$ has no more than two nonzero entries, each of which is $-\frac{1}{4}$, it follows that $\lVert B \rVert_1 = \frac{1}{2} < 1$. Thus, by condition (c) of the given Theorem, the Jacobi method converges.
	
	\question
	Rewriting the system of equations in matrix-vector form $Ax = b$, we must have
	\begin{equation}
		A = \left(\begin{matrix}
			1 & 0 & 1\\
			-1 & 1 & 0 \\
			1 & 2 & -3
		\end{matrix}\right), \qquad b = \left(\begin{matrix}
			0 \\ 0 \\ 0
		\end{matrix}\right).
	\end{equation}
	Suppose that the Jacobi method for $Ax = b$ is given by $x^{(k+1)} = B_Jx^{(l)} + c_J$, and the Gauss-Seidel method for $Ax=b$ is given by $x^{(k+1)}=B_Gx^{(k)} + c_G$. Recalling computations from Homework 9, we have
	\begin{equation}
		B_J = \left(\begin{matrix}
			0 & 0 & 1\\
			-1 &0 & 0\\
			-\frac{1}{3} & -\frac{2}{3} & 0
		\end{matrix}\right),\qquad
		B_G = \left(\begin{matrix}
			0 & 0 & -1\\
			0 & 0 & -1\\
			0 & 0 & -1
		\end{matrix}\right).
	\end{equation}
	For $B_J$, the eigenvalues are the roots $\lambda$ of the equation $\lambda\left(\lambda^2 +\frac{2}{3}\right) + \frac{2}{3} = 0$. Using MATLAB to find the roots of this equation, we see that the maximum modulus of the eigenvalues is around 0.944, so $\rho(B_J) < 1$. Thus, part (b) of the given Theorem implies that the Jacobi method for this problem converges, which is consistent with the numerical behavior observed in Homework 9.
	
	For $B_G$, note that our initial point $x_0 = (1,1,1)^T$ is an eigenvector with corresponding eigenvalue $-1$:
	\begin{equation}
		\label{eq:bg_ev}
		B_Gx_0 = -x_0.
	\end{equation}
	Therefore, $\rho(B_G) \ge 1$, and part (b) of the given Theorem implies that the Gauss-Seidel method may not converge for this problem. Indeed, the equation (\ref{eq:bg_ev}) explains why the Gauss-Seidel method simply oscillated back and forth between $x_0$ and $-x_0$ in Homework 9 (note that $c_G = 0$).
\end{document}