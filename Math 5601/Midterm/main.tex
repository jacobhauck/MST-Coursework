\documentclass{homework}
\input{../homework_shared.tex}
\input{../../standardcmd.tex}

\renewcommand{\hwtype}{Midterm Project}
\newcommand{\hwnum}{}
\renewcommand{\questiontype}{Problem}


\begin{document}
	\maketitle
	
	Throughout this project, we consider the IVP
	\begin{alignat}{2}
		\label{eq:ivp_ode}
		y' &= f(t, y),&\qquad &a \le t \le b\\
		\label{eq:ivp_ic}
		y(a) &= g_a,&\qquad &g_a \in \R.
	\end{alignat}
	We also use the mesh with sample points $t_j = a + jh$, with $t_0 = a$, where $h > 0$ is the step size. Lastly, we assume that $f$ is $L$-Lipschitz in $y$ uniformly for $t \in [a,b]$ (so that the solution of (\ref{eq:ivp_ode}-\ref{eq:ivp_ic}) is unique).
	
	\question
	Using the Taylor expansion for $y$ about $t_j$, we get
	\begin{equation}
		\label{p1:eq:expand_right}
		y(t_{j+1}) = y(t_j) + hy'(t_j) + \frac{h^2}{2}y''(t_j) + \bigoh(h^3).
	\end{equation}
	Similarly, expanding $y$ about $t_{j+1}$ gives
	\begin{equation}
		y(t_j) = y(t_{j+1}) - hy'(t_{j+1}) + \frac{h^2}{2}y''(t_{j+1}) + \bigoh(h^3).
	\end{equation}
	Further expanding $y''$ about $t_j$, we get
	\begin{align}
		y(t_j) &= y(t_{j+1}) - hy'(t_{j+1}) + \frac{h^2}{2}\left(y''(t_j) + \bigoh(h)\right) + \bigoh(h^3) \\
		\label{p1:eq:expand_left}
		&= y(t_{j_1}) - hy'(t_{j+1}) + \frac{h^2}{2}y''(t_j) + \bigoh(h^3).
	\end{align}
	Rearranging (\ref{p1:eq:expand_left}) and (\ref{p1:eq:expand_right}) and substituting from (\ref{eq:ivp_ode}), we get
	\begin{alignat}{2}
		\label{p1:eq:est_left}
		\frac{y(t_{j+1}) - y(t_j)}{h} &= y'(t_j) + \frac{h}{2}y''(t_j) + \bigoh(h^2)&& = f(t_j, y(t_j)) + \frac{h}{2} y''(t_j) + \bigoh(h^2), \\
		\label{p1:eq:est_right}
		\frac{y(t_{j+1}) - y(t_j)}{h} &= y'(t_{j+1}) - \frac{h}{2}y''(t_j) + \bigoh(h^2)&& = f(t_{j+1}, y(t_{j+1})) - \frac{h}{2}y''(t_j) + \bigoh(h^2).
	\end{alignat}
	If we take the average of both sides of (\ref{p1:eq:est_left}) and (\ref{p1:eq:est_right}), then we finally obtain
	\begin{equation}
		\frac{y(t_{j+1}) - y(t_j)}{h} = \frac{f(t_{j+1}, y(t_{j+1})) + f(t_j, y(t_j))}{2} + \bigoh(h^2).
	\end{equation}
	Thus, if $y_j = y(t_j)$ and we compute $y_{j+1}$ using the trapezoidal scheme, that is, as the solution of
	\begin{equation}
		\label{eq:trapezoidal}
		y_{j+1} = y_j + h\cdot\frac{f(t_{j+1}, y_{j+1}) + f(t_j, y_j)}{2},
	\end{equation}
	then $y_{j+1}$ (assuming the solution of (\ref{eq:trapezoidal}) is unique) will satisfy the estimate
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = \frac{h}{2}\cdot|f(t_{j+1}, y(t_{j+1})) - f(t_{j+1}, y_{j+1})| + \bigoh(h^3).
	\end{equation}
	Using the Lipschitz property of $f$, we obtain
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| \le \frac{hL}{2}\cdot|y_{j+1} - y(t_{j+1})| + \bigoh(h^3),
	\end{equation}
	so
	\begin{equation}
		|y_{j+1}-y(t_{j+1})| \cdot\left(1 - \frac{hL}{2}\right) \le \bigoh(h^3).
	\end{equation}
	As $h \to 0$, the quantity $1 - \frac{hL}{2} \to 1$; therefore,
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = \bigoh(h^3).
	\end{equation}
	That is, the \textit{local truncation error} of the trapezoidal scheme is of order 3, which means that the accuracy of the method as a whole is of order 2.
	
	\question 
	Consider the Taylor expansion of $y$ about $t_{j+1}$ at the points $t_{j-1}$, $t_j$ and $t_{j+1}$:
	\begin{align}
		y(t_{j-1}) &= y(t_{j+1}) - 2hy'(t_{j+1}) + 2h^2y''(t_{j+1}) + \bigoh(h^3) \\
		y(t_j) &= y(t_{j+1}) - hy'(t_{j+1}) + \frac{h^2}{2}y''(t_{j+1}) + \bigoh(h^3) \\
		y(t_{j+1}) &= y(t_{j+1}).
	\end{align}
	If we form the linear combination $3y(t_{j+1}) - 4y(t_j) + y(t_{j-1})$, then we get
	\begin{alignat}{2}
		3y(t_{j+1}) - 4y(t_j) + y(t_{j-1}) &{}={} &&3y(t_{j+1})\\
		&& {}-{} &4y(t_{j+1}) + 4hy'(t_{j+1}) - 2y''(t_{j+1})h^2 \\
		&&{}+{}&y(t_j)-2hy'(t_j) + 2y''(t_j)h^2 + \bigoh(h^3).
	\end{alignat}
	Therefore, canceling terms and substituting from (\ref{eq:ivp_ode}), we have
	\begin{equation}
		3y(t_{j+1}) - 4y(t_j) + y(t_{j-1}) = hf(t_{j+1}, y(t_{j+1})) + \bigoh(h^3)
	\end{equation}
	Thus, if we know that $y_{j-1} = y(t_{j-1})$, and $y(t_j) = y_j$ and we compute $y_{j+1}$ using the two-step backward differentiation scheme, that is, as the solution of
	\begin{equation}
		\label{p2:eq:2_step_backward}
		\frac{3y_{j+1} -4t_j + y_{j-1}}{2h} = hf(t_{j+1},y_{j+1}),
	\end{equation}
	then the local truncation error $|y_{j+1} - y(t_{j+1})|$ will satisfy
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = h|f(t_{j+1}, y_{j+1}) - f(t_{j+1}, y(t_{j+1}))| + \bigoh(h^3).
	\end{equation}
	By the Lipschitz property of $f$,
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| \le hL|y_{j+1}-y(t_{j1+})| + \bigoh(h^3),
	\end{equation}
	so
	\begin{equation}
		|y_{j+1} - y(t_{j+1})|(1-hL) \le \bigoh(h^3).
	\end{equation}
	As $h \to 0$, the quantity $(1-hL) \to 1$; therefore,
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = \bigoh(h^3).
	\end{equation}
	That is, the \textit{local trunction error} of the two-step backward differentiation scheme is of order 3, and the accuracy of the method as a whole is of order 2.
	
	\question
	Consider the Taylor expansions of $y(t_{j+1})$, $y(t_j)$, $y(t_{j-1})$, and $y(t_{j-2})$ about $t_{j+1}$:
	\begin{align}
		y(t_{j+1}) &= y(t_{j+1}) \\
		y(t_j) &= y(t_{j+1}) - hy'(t_{j+1}) + \frac{h^2}{2}y''(t_{j+1}) - \frac{h^3}{6}y'''(t_{j+1}) + \bigoh(h^4) \\
		y(t_{j-1}) &= y(t_{j+1}) - 2hy'(t_{j+1}) + 2h^2y''(t_{j+1}) - \frac{4h^3}{3}y'''(t_{j+1}) + \bigoh(h^4) \\
		y(t_{j-2}) &= y(t_{j+1}) - 3hy'(t_{j+1}) + \frac{9h^2}{2}y''(t_{j+1}) - \frac{9h^3}{2}y'''(t_{j+1}) + \bigoh(h^4)
	\end{align}
	Then, for $\beta_1, \beta_2, \beta_3, \beta_4 \in \R$,
	\begin{align}
		\beta_1 y(t_{j+1}) + \beta_2 y(t_j) &+ \beta_3 y(t_{j-1}) + \beta_4 y(t_{j-2}) = \\
		&\quad(\beta_1 + \beta_2+ \beta_3 + \beta_4)y(t_{j+1}) \\ &- (\beta_2 + 2\beta_3 + 3\beta_4)y'(t_{j+1})h \\ &+ \frac{1}{2}(\beta_2 + 4\beta_3 + 9\beta_4)y''(t_{j+1})h^2 \\ &- \frac{1}{6}(\beta_2 + 8\beta_3 + 27\beta_4)y'''(t_{j+1})h^3 + \bigoh(h^4).
	\end{align}
	To cancel the lower-order terms, we must choose $\beta_2$, $\beta_3$, and $\beta_4$ such that
	\begin{equation}
		\label{p3:eq:beta_requirements}
		\begin{aligned}
			-1 &= \beta_2 + \beta_3 + \beta_4 \\
			0 &= \beta_2 + 4\beta_3 + 9\beta_4 \\
			0 &= \beta_2 + 8\beta_3 + 27\beta_4,
		\end{aligned}
	\end{equation}
	then we get
	\begin{equation}
		\label{p3:eq:three_step_bdf_est}
		\frac{y(t_{j+1}) + \beta_2y(t_j) + \beta_3y(t_{j-1}) + \beta_4y(t_{j-2})}{-(\beta_2 + 2\beta_3 + 3\beta_4)h} = y'(t_{j+1}) + \bigoh(h^4) = f(t_{j+1}, y(t_{j+1})) + \bigoh(h^3).
	\end{equation}
	To satisfy (\ref{p3:eq:beta_requirements}), we must have $4\beta_3 + 9\beta_4 = 8\beta_3 + 27\beta_4$, so $\beta_3 = -\frac{9}{2}\beta_4$. Then $\beta_2 = 18\beta_4 - 9\beta_4 = 9\beta_4$, and $-1 = 9\beta_4 - \frac{9}{2}\beta_4 + \beta_4 = \frac{11}{2}\beta_4$, so $\beta_4 = -\frac{2}{11}$. Then $\beta_3 = \frac{9}{11}$, and $\beta_2 = -\frac{18}{11}$. Lastly, $-(\beta_2 + 2\beta_3 + 3\beta_4) = \frac{6}{11}$.
	
	If we set 
	\begin{align}
		\alpha_1 &= \frac{1}{-(\beta_2 + 2\beta_3 + 3\beta_4)} = \frac{11}{6} \\
		\alpha_2 &= \frac{\beta_2}{-(\beta_2 + 2\beta_3 + 3\beta_4)} = -\frac{18}{6}\\
		\alpha_3 &= \frac{\beta_3}{-(\beta_2 + 2\beta_3 + 3\beta_4)} = \frac{9}{6}\\
		\alpha_4 &= \frac{\beta_4}{-(\beta_2 + 2\beta_3 + 3\beta_4)} = -\frac{2}{6},
	\end{align}
	then by (\ref{p3:eq:three_step_bdf_est}),
	\begin{equation}
		\frac{\alpha_1y(t_{j+1}) + +\alpha_2y(t_j) +\alpha_3y(t_{j-1}) + \alpha_4y(t_{j-2})}{h} = f(t_{j+1},y(t_{j+1})) + \bigoh(h^3).
	\end{equation}
	If we had $y_{j-2} = y(t_{j-2})$, $y_{j-1} = y(t_{j-1})$, and $y_j = y(t_j)$, and we computed $y_{j+1}$ as the solution of
	\begin{equation}
		\frac{\alpha_1y(t_{j+1}) + +\alpha_2y(t_j) +\alpha_3y(t_{j-1}) + \alpha_4y(t_{j-2})}{h} = f(t_{j+1}, y_{j+1}),
	\end{equation}
	then $|y_{j+1} - y(t_{j+1})$ would satisfy
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = |f(t_{j+1}, y_{j+1}) - f(t_{j+1}, y(t_{j+1}))| + \bigoh(h^3).
	\end{equation}
	Using the Lipschitz property of $f$, we obtain
	\begin{equation}
		|y_{j+1} - y(t_{j+1})|(1-hL) \le \bigoh(h^4).
	\end{equation}
	As $h\to 0$, the quantity $1-hL \to 1$; therefore,
	\begin{equation}
		|y_{j+1} - y(t_{j+1})| = \bigoh(h^3).
	\end{equation}
	That is, the implicit scheme
	\begin{equation}
		\label{p3:eq:3_step_bdf_scheme}
		\frac{\alpha_1y(t_{j+1}) + +\alpha_2y(t_j) +\alpha_3y(t_{j-1}) + \alpha_4y(t_{j-2})}{h} = f(t_{j+1}, y_{j+1})
	\end{equation}
	with $\alpha_1 = \frac{11}{6}$, $\alpha_2 = -\frac{18}{6}$, $\alpha_3 = \frac{9}{6}$, and $\alpha_4 = -\frac{2}{6}$ has 3rd-order accuracy. Since we had to choose these values of $\alpha$ to cancel higher-order terms, these must be the coefficients in the third-order backward differentiation scheme.
	\\
	\hrule
	
	We now consider Newton's method for finding the root of a function $f$:
	\begin{equation}
		x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}.
	\end{equation}
	
	\question
	Suppose that $f$ has a root $z$ of multiplicity $m \ge 2$. Then, by definition, there exists a function $r$ such $r(z) \ne 0$, and $f(x) = (x-z)^mr(x)$. Then $f'(x) =m(x-z)^{m-1}r(x) + (x-z)^mr'(x) = (x-z)^{m-1}(mr(x) + (x-z)r'(x))$. Then we can still safely define Newton's method despite the fact that $f'(z) = 0$ by setting
	\begin{equation}
		g(x) = x - \frac{f(x)}{f'(x)} = x - \frac{(x-z)^mr(x)}{(x-z)^{m-1}(mr(x) + (x-z)r'(x))} = x- \frac{(x-z)r(x)}{mr(x) + (x-z)r'(x)}
	\end{equation}
	and observing that the denominator in the last expression is nonzero when $x =z$ because $r(z) \ne 0$. Then Newton's method becomes $x_{k+1} = g(x_k)$.
	
	To apply the theory of convergence in the project description, we need to compute
	\begin{equation*}
		g'(x) = 1 - \frac{(r(x) + (x-z)r'(x))(mr(x) + (x-z)r'(x)) - (x-z)r(x)(mr'(x) + r'(x) + (x-z)r''(x))}{(mr(x) + (x-z)r'(x))^2}
	\end{equation*}
	so that
	\begin{equation}
		g'(z) = 1 - \frac{m(r(z))^2}{(mr(z))^2} = 1 - \frac{1}{m}
	\end{equation}
	since $r(z) \ne 0$. Since $g'(z) \ne 0$ if $m \ge 2$, but $|g'(z)| < 1$, it follows by the convergence theorem in the project description that Newton's method has \textit{linear} convergence in this case.
	
	\question
	In the case that $f$ has a root $z$ of multiplicity $m \ge 2$, we saw that Newton's method defined by $x_{k+1} = g(x_k)$, where
	\begin{equation}
		g(x) = x - \frac{(x-z)r(x)}{mr(x) + (x-z)r'(x)}
	\end{equation}
	had a linear convergence rate to the root $z$ of $f$. We can fix this simply by adjusting Newton's method to
	\begin{equation}
		x_{k+1} = x_k - m\frac{f(x_k)}{f'(x_k)},
	\end{equation}
	that is, by replacing $g$ by $g_m$, where
	\begin{equation}
		g_m(x) = x - m\frac{(x-z)r(x)}{mr(x) + (x-z)r'(x)}.
	\end{equation}
	This method has at least quadratic convergence by the convergence theorem in the project description because
	\begin{equation*}
		g_m'(x) = 1 - m\frac{(r(x) + (x-z)r'(x))(mr(x) + (x-z)r'(x)) - (x-z)r(x)(mr'(x) + r'(x) + (x-z)r''(x))}{(mr(x) + (x-z)r'(x))^2}
	\end{equation*}
	so that
	\begin{equation}
		g_m'(z) = 1-  m\frac{m(r(z))^2}{(mr(z))^2} = 0.
	\end{equation}
	Then the iteration $x_{k+1} = g_m(x_k)$ converges at least quadratically to the root $z$ of $f$ by the convergence theorem in the project description.
	\\
	\hrule
	
	Now we consider the implementation of the backward Euler method for (\ref{eq:ivp_ode}, \ref{eq:ivp_ic}):
	\begin{equation}
		y_0 = y(a) = g_a, \qquad y_{j+1} = y_j + hf(t_{j+1}, y_{j+1}) \quad\text{if}\quad j \in \{0,1,\dots, J-1\}.
	\end{equation}
	
	\question
	\newcommand{\newf}{\tilde{f}}
	\newcommand{\newg}{\tilde{g}}
	Suppose that $y_j$, $t_{j+1}$ and $h$ are known at the $j$th step of the backward Euler method. Then $y_{j+1}$ can be obtained by solving the nonlinear equation
	\begin{equation}
		\label{eq:p6:equation_to_solve}
		y_{j+1} = y_j + hf(t_{j+1}, y_{j+1})
	\end{equation}
	for $y_{j+1}$. Since our methods for numerically solving nonlinear equations work only for equations of the form $\newf(x) = 0$ (for the bisection, Netwton's and secant methods) and $\newg(x) = x$ (for the fixed point method), we need to recast (\ref{eq:p6:equation_to_solve}) in these forms. In other words, we need to define $\newf$ and $\newg$ such that
	\begin{equation}
		\newf(y_{j+1}) = 0 \iff y_{j+1} = y_j + hf(t_{j+1}, y_{j+1}) \iff \newg(y_{j+1}) = y_{j+1}.
	\end{equation}
	There are many ways to do this, but perhaps the simplest is to choose
	\begin{equation}
		\newf(x) = x - y_j - hf(t_{j+1}, x),\qquad \newg(x) = y_j + hf(t_{j+1}, x).
	\end{equation}
	
	\question
	Suppose that we wanted to use the bisection method or the secant method to solve $x = y_j + hf(t_{j+1}, x)$ for $x$.
	\begin{alphaparts}
		\questionpart To use the bisection method, we would need to know
		\begin{enumerate}[label=(\arabic*)]
			\item the initial interval $[a,b]$ that contains the root, and
			\item the stopping conditions (error tolerances and maximum iterations).
		\end{enumerate}
		As mentioned in the project description, the stopping conditions can be set according to the accuracy requirements determined by the step size $h$. The initial interval, however, would be more difficult to determine.
		
		\questionpart
		To use the secant method, we would need to know
		\begin{enumerate}[label=(\arabic*)]
			\item the initial points $x_0$ and $x_1$, and
			\item the stopping conditions (error tolerances and maximum iterations).
		\end{enumerate}
		As with the bisection method, the stopping conditions here can be determined fairly easily. The two initial points, however, would be more difficult to choose. Perhaps $x_0 = y_{j-1}$ and $x_1 = y_j$ would work, but we would still need to answer the question of how to choose $x_0$ when $j=0$.
	\end{alphaparts}
	
	\question
	\begin{alphaparts}
		\questionpart
		
	\end{alphaparts}
\end{document}