@article{_2023h,
  title = {Sherman\textendash{{Morrison}} Formula},
  year = {2023},
  month = oct,
  journal = {Wikipedia},
  urldate = {2023-11-08},
  abstract = {In mathematics, in particular linear algebra, the Sherman\textendash Morrison formula, named after Jack Sherman and Winifred J. Morrison, computes the inverse of the sum of an invertible matrix                         A                 \{\textbackslash displaystyle A\}    and the outer product,                         u                    v                                       T                                                  \{\textbackslash displaystyle uv\^\{\textbackslash textsf \{T\}\}\}   , of vectors                         u                 \{\textbackslash displaystyle u\}    and                         v                 \{\textbackslash displaystyle v\}   . The Sherman\textendash Morrison formula is a special case of the Woodbury formula.  Though named after Sherman and Morrison, it appeared already in earlier publications.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1181851689},
  file = {C:\Users\hauck\Zotero\storage\I72WV8ES\index.html}
}

@article{_2023i,
  title = {Hadamard's Inequality},
  year = {2023},
  month = sep,
  journal = {Wikipedia},
  urldate = {2023-11-08},
  abstract = {In mathematics, Hadamard's inequality (also known as Hadamard's theorem on determinants) is a result first published by Jacques Hadamard in 1893. It is a bound on the determinant of a matrix whose entries are complex numbers in terms of the lengths of its column vectors. In geometrical terms, when restricted to real numbers, it bounds the volume in Euclidean space of n dimensions marked out by n vectors vi for 1 {$\leq$} i {$\leq$} n in terms of the lengths of these vectors ||vi||. Specifically, Hadamard's inequality states that if N is the matrix having columns vi,  then                                   |                        det             (             N             )                      |                  {$\leq$}                    {$\prod$}                        i             =             1                                   n                             {$\Vert$}                    v                        i                             {$\Vert$}         .                 \{\textbackslash displaystyle \textbackslash left|\textbackslash det(N)\textbackslash right|\textbackslash leq \textbackslash prod \_\{i=1\}\^\{n\}\textbackslash |v\_\{i\}\textbackslash |.\}   If the n vectors are non-zero, equality in Hadamard's inequality is achieved if and only if the vectors are orthogonal.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1173811623},
  file = {C:\Users\hauck\Zotero\storage\B9P7SN8J\Hadamard's_inequality.html}
}

@article{bartlett_1951,
  title = {An {{Inverse Matrix Adjustment Arising}} in {{Discriminant Analysis}}},
  author = {Bartlett, M. S.},
  year = {1951},
  month = mar,
  journal = {The Annals of Mathematical Statistics},
  volume = {22},
  number = {1},
  pages = {107--111},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177729698},
  urldate = {2023-11-22},
  langid = {english},
  file = {C:\Users\hauck\Zotero\storage\7M5JNDRW\1177729698.pdf}
}

@inbook{goreinov_2010,
  title = {How to {{Find}} a {{Good Submatrix}}},
  booktitle = {Matrix {{Methods}}: {{Theory}}, {{Algorithms}} and {{Applications}}},
  author = {Goreinov, S. A. and Oseledets, I. V. and Savostyanov, D. V. and Tyrtyshnikov, E. E. and Zamarashkin, N. L.},
  year = {2010},
  month = apr,
  pages = {247--256},
  publisher = {{WORLD SCIENTIFIC}},
  doi = {10.1142/9789812836021_0015},
  urldate = {2023-11-07},
  collaborator = {Olshevsky, Vadim and Tyrtyshnikov, Eugene},
  isbn = {978-981-283-601-4 978-981-283-602-1},
  langid = {english},
  file = {C:\Users\hauck\Zotero\storage\V888MT3M\08-10.pdf}
}

@misc{hamm_2022,
  title = {Generalized {{Pseudoskeleton Decompositions}}},
  author = {Hamm, Keaton},
  year = {2022},
  month = jun,
  number = {arXiv:2206.14905},
  eprint = {2206.14905},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2023-11-27},
  abstract = {We characterize some variations of pseudoskeleton (also called CUR) decompositions for matrices and tensors over arbitrary fields. These characterizations extend previous results to arbitrary fields and to decompositions which use generalized inverses of the constituent matrices, in contrast to Moore--Penrose pseudoinverses in prior works which are specific to real or complex valued matrices, and are significantly more structured.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Numerical Analysis},
  file = {C\:\\Users\\hauck\\Zotero\\storage\\E8RYSFDS\\Hamm - 2022 - Generalized Pseudoskeleton Decompositions.pdf;C\:\\Users\\hauck\\Zotero\\storage\\ZRTCA6Z6\\2206.html}
}

@book{meyer_2008,
  title = {Matrix Analysis and Applied Linear Algebra},
  author = {Meyer, Carl D.},
  year = {2008},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-454-8},
  langid = {english},
  file = {C:\Users\hauck\Zotero\storage\UK4A44P7\Meyer - 2008 - Matrix analysis and applied linear algebra.pdf}
}

@article{oseledets_2010a,
  title = {{{TT-cross}} Approximation for Multidimensional Arrays},
  author = {Oseledets, Ivan and Tyrtyshnikov, Eugene},
  year = {2010},
  month = jan,
  journal = {Linear Algebra and its Applications},
  volume = {432},
  number = {1},
  pages = {70--88},
  issn = {00243795},
  doi = {10.1016/j.laa.2009.07.024},
  urldate = {2023-10-13},
  abstract = {As is well known, a rank-r matrix can be recovered from a cross of r linearly independent columns and rows, and an arbitrary matrix can be interpolated on the cross entries. Other entries by this cross or pseudo-skeleton approximation are given with errors depending on the closeness of the matrix to a rank-r matrix and as well on the choice of cross. In this paper we extend this construction to d-dimensional arrays (tensors) and suggest a new interpolation formula in which a d-dimensional array is interpolated on the entries of some TT-cross (tensor-train-cross). The total number of entries and the complexity of our interpolation algorithm depend on d linearly, so the approach does not suffer from the curse of dimensionality.},
  langid = {english},
  file = {C:\Users\hauck\Zotero\storage\S7WN3EH7\1-s2.0-S0024379509003747-main.pdf}
}

@book{parlett_1998,
  title = {The Symmetric Eigenvalue Problem},
  author = {Parlett, Beresford N.},
  year = {1998},
  series = {Classics in Applied Mathematics},
  number = {20},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-402-9},
  lccn = {QA188 .P37 1998},
  keywords = {Eigenvalues,Symmetric matrices},
  file = {C:\Users\hauck\Zotero\storage\UBZAYV2M\(Classics in Applied Mathematics) Beresford N. Parlett - The Symmetric Eigenvalue Problem -Society for Industrial  Mathematics (1987).pdf}
}

@article{sekmen_,
  title = {Matrix {{Reconstruction}}: {{Skeleton Decomposition}} versus {{Singular Value Decomposition}}},
  author = {Sekmen, Ali and Aldroubi, Akram and Koku, Ahmet Bugra and Hamm, Keaton},
  abstract = {In this work, Skeleton Decomposition (SD) and Singular Value Decomposition (SVD) are compared and evaluated for reconstruction of data matrices whose columns come from a union of subspaces. Specifically, an original data matrix is reconstructed from noise-contaminated version of it. First, matrix reconstruction using SD iteratively is introduced and alternative methods for forming SD-based reconstruction are discussed. Then, through exhaustive simulations, effects of process parameters such as noise level, data size, number of subspaces and their dimensions are evaluated for reconstruction performance. It is also shown that SD-based reconstruction is more effective when data is drawn from a union of low dimensional subspaces compared to a single space of the same dimension.},
  langid = {english},
  file = {C:\Users\hauck\Zotero\storage\E7EZY9NV\Sekmen et al. - Matrix Reconstruction Skeleton Decomposition vers.pdf}
}
